{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9342a38b",
   "metadata": {},
   "source": [
    "### Importing Machine Learning Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea6092e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns # used for plot interactive graph. \n",
    "import seaborn as sns\n",
    "import streamlit as st \n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fe5650e0",
   "metadata": {},
   "source": [
    "### Reads an Excel file for performing classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86a63cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"/home/kushal/Documents/projects/tf-idf-implementation/data/ConcatenatedDigitalAdData.xlsx\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1141cc66",
   "metadata": {},
   "source": [
    "### Creating a new column in the DataFrame called \"TitleandDesc\" by concatenating the values of the \"title\" and \"Job_Description\" columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097801cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"TitleandDesc\"] = df[\"title\"] + df[\"Job_Description\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf6a9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"TitleandDesc\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c9d5027b",
   "metadata": {},
   "source": [
    "### Cleaning and Preprocessing the data before further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1903214d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Index', 'title','url','Posted-Date', 'Job_Description'], axis=1, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fc2d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_column = df.pop('TitleandDesc')\n",
    "df.insert(0, 'TitleandDesc', first_column)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2114084f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57a695c",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = df['TitleandDesc'].notnull().sum()\n",
    "round((total/len(df)*100),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f99a7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head(15)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "150ae07a",
   "metadata": {},
   "source": [
    "### Displaying the class 'JobType'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7ef4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(df.JobType.unique()).values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2f50ba4b",
   "metadata": {},
   "source": [
    "### Calculating the number of data belonging to the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397b7e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "Counter(df[\"JobType\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f02510c7",
   "metadata": {},
   "source": [
    "### Making ease to feed to Machine Learning\n",
    "Categorical variables such as 'JobType' cannot be directly used in many machine learning algorithms, as they are typically designed to work with numerical data. In order to use the 'JobType' column in these algorithms, it needs to be converted to numerical form. One way to do this is through a process called factorization, which assigns a unique integer value to each unique category. This allows for the categorical data to be used in machine learning algorithms as numerical data.\n",
    "\n",
    "Additionally, creating the dictionaries 'job_to_id' and 'id_to_job' allows for easy mapping between the original categorical values and the numerical values. This will be useful for interpreting the results of the model later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b54a177",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Job_Id'] = df['JobType'].factorize()[0]\n",
    "job_id_df = df[['JobType', 'Job_Id']].drop_duplicates()\n",
    "\n",
    "\n",
    "# Dictionaries for future use\n",
    "job_to_id = dict(job_id_df.values)\n",
    "id_to_job = dict(job_id_df[['Job_Id', 'JobType']].values)\n",
    "\n",
    "# New dataframe\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "76f73763",
   "metadata": {},
   "source": [
    "### Checking for missing values in Dataframe\n",
    "**If there are no mising values, it returns '0'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b905fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b63f4b6e",
   "metadata": {},
   "source": [
    "### Distribution of different JobTypes in the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114b4bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,6))\n",
    "colors = ['red', 'blue', 'green', 'grey', 'darkblue']\n",
    "df.groupby('JobType').TitleandDesc.count().sort_values().plot.barh(\n",
    "    ylim=0, color=colors, title= 'No. of Jobs in Each JobType \\n')\n",
    "plt.xlabel('Number of ocurrences', fontsize = 10);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9959c180",
   "metadata": {},
   "source": [
    "### Feature Extraction \n",
    "Using **TfidfVectorizer** from scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4902b45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5,\n",
    "                        ngram_range=(1, 3), \n",
    "                        stop_words='english')\n",
    "\n",
    "# We transform each complaint into a vector\n",
    "features = tfidf.fit_transform(df.TitleandDesc).toarray()\n",
    "\n",
    "labels = df.Job_Id\n",
    "\n",
    "print(\"Each of the %d complaints is represented by %d features (TF-IDF score of unigrams and bigrams)\" %(features.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd3da94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf26b836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8bd71c21",
   "metadata": {},
   "source": [
    "### Generating Unigrams and Bigrams\n",
    "Performing feature selection using chi-squared test on the Tf-Idf features and labels. It prints the top N correlated unigrams, and bigrams for each JobType.\n",
    "This is done to improve the performance of text classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497b233a",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 5\n",
    "for JobType, Job_Id in sorted(job_to_id.items()):\n",
    "    features_chi2 = chi2(features, labels == Job_Id)\n",
    "    indices = np.argsort(features_chi2[0])\n",
    "    \n",
    "    vocab = {v: k for k, v in tfidf.vocabulary_.items()}\n",
    "    feature_names = [vocab[i] for i in indices]   \n",
    "     \n",
    "    unigrams = [v for v in feature_names if len(v.split(' ')) == 1]\n",
    "    bigrams = [v for v in feature_names if len(v.split(' ')) == 2]\n",
    "\n",
    "    print(\"\\n==> %s:\" %(JobType))\n",
    "    \n",
    "    print(\"  * Most Correlated Unigrams are: %s\" %(', '.join(unigrams[-N:])))\n",
    "    print(\"  * Most Correlated Bigrams are: %s\" %(', '.join(bigrams[-N:])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77149f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(df[\"TitleandDesc\"])\n",
    "y = np.array(df[\"JobType\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a23390",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_types = pd.DataFrame(df.JobType.unique()).values.tolist()\n",
    "job_types\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7f9c64f9",
   "metadata": {},
   "source": [
    "### Train Test Split\n",
    "Splitting the data into training and testing sets for model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc1be1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=45)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4a51f009",
   "metadata": {},
   "source": [
    "### OneVsRestClassifier \n",
    "The OneVsRestClassifier is a class in scikit-learn that allows for multi-label classification by training a binary classifier for each label separately, and then using these binary classifiers to make predictions for new instances. It is used for multi-class problems.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d9a81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline of feature engineering and model\n",
    "model = Pipeline([('vectorizer', CountVectorizer()),\n",
    " ('tfidf', TfidfTransformer()),\n",
    " ('clf', OneVsRestClassifier(LinearSVC(class_weight='balanced')))])\n",
    "#the class_weight=\"balanced\" option tries to remove the biasedness of model towards majority sample\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cee40622",
   "metadata": {},
   "source": [
    "### Training the Text Classification Model on the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ee7357",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#fit model with training data\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "80e76826",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n",
    "A confusion matrix is a table that is used to define the performance of a classification algorithm. It gives an idea of how well the algorithm is classifying the problem by comparing the predicted values with the true values in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609b763e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "sns.heatmap(\n",
    "    conf_mat, \n",
    "    annot=True, \n",
    "    cmap=\"Blues\", \n",
    "    fmt='d',\n",
    "    xticklabels=job_id_df.JobType.values, \n",
    "    yticklabels=job_id_df.JobType.values\n",
    ")\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title(\"CONFUSION MATRIX \\n\", size=16);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "908c83df",
   "metadata": {},
   "source": [
    "### Classification Report\n",
    "It is a summary of the performance of a classifier for a classification problem. It displays several evaluation metrics for each class, including precision, recall, f1-score and support. It is a text report that contains several evaluation metrics for each class and it helps to understand the performance of a classifier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33f2ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\t\\t\\tCLASSIFICATIION METRICS\\n')\n",
    "print(classification_report(\n",
    "        y_test, \n",
    "        y_pred, \n",
    "        target_names = df['JobType'].unique()\n",
    "    )\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6b2b2569",
   "metadata": {},
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830defc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = '/home/kushal/Documents/projects/tf-idf-implementation/model/adv_model.sav'\n",
    "# pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "239e012e",
   "metadata": {},
   "source": [
    "### Load The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b814950c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7b15289e",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64094d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = loaded_model.score(X_test, y_test)\n",
    "print(f\"The Accuracy of the Classification is:  {round(result*100, 3)}%\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7c4634c3",
   "metadata": {},
   "source": [
    "### Sample Input and Testing The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6aed07",
   "metadata": {},
   "outputs": [],
   "source": [
    "job = input(\"Enter the text that we need to classify\")\n",
    "print(job)\n",
    "model.predict([job])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85eca52a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
